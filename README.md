ğŸ›ï¸ Black Friday Sales Prediction
ğŸ“Œ Project Overview

This project predicts customer purchase amount during Black Friday sales using machine learning.
It follows a progressive modeling approach, starting from simple baselines and moving toward advanced gradient boosting models, with CatBoost selected as the final model due to its superior performance on categorical-heavy data.

ğŸ¯ Problem Statement

Given customer demographics and product information, predict the purchase amount (Purchase).

Type: Supervised Learning

Task: Regression

ğŸ“‚ Dataset Description

The dataset contains customer and product-level data collected during Black Friday sales.

Key Features

Gender

Age

Occupation

City_Category

Stay_In_Current_City_Years

Product_Category_1/2/3

Purchase (target)

Identifier columns (User_ID, Product_ID) were removed as they do not contribute predictive value.

ğŸ§¹ Data Preprocessing

Removed identifier columns to prevent noise and leakage

Handled missing values using appropriate imputation strategies

Separated target variable before preprocessing

Used trainâ€“test split prior to scaling and modeling

ğŸ“Š Exploratory Data Analysis (EDA)

EDA was performed to:

Analyze purchase distribution

Study the impact of demographics and product categories

Identify skewness and spending patterns

Key insights:

Purchase values are right-skewed

Product categories strongly influence spending

Customer attributes show clear behavioral trends

âš™ï¸ Feature Engineering

One-Hot Encoding for categorical features

Proper handling of numerical features

Ensured no target leakage during preprocessing

ğŸ§  Modeling Strategy (Progressive Approach)

The project followed an iterative model improvement pipeline:

1ï¸âƒ£ Baseline Model

Mean purchase predictor

MAE â‰ˆ 4000

2ï¸âƒ£ Linear Regression

Simple interpretable model

Struggled with non-linear relationships

MAE â‰ˆ 3500

3ï¸âƒ£ Random Forest Regressor

Captured non-linear interactions

Significant improvement

MAE â‰ˆ 2200

4ï¸âƒ£ XGBoost Regressor

Gradient boosting for better biasâ€“variance tradeoff

Improved handling of complex patterns

Further reduced error compared to Random Forest

5ï¸âƒ£ CatBoost Regressor (Final Model) âœ…

Why CatBoost?

Handles categorical features efficiently

Reduces need for heavy preprocessing

Strong performance on tabular data

Robust against overfitting

MAE â‰ˆ 2100

ğŸ‘‰ Best overall performance achieved with CatBoost

ğŸ”— Pipeline Architecture

A full scikit-learn pipeline was used to ensure:

Clean preprocessing

Consistent transformations

No data leakage

Reproducibility

Pipeline Flow
Raw Data
 â†’ Imputation
 â†’ Encoding
 â†’ Model Training
 â†’ Prediction

ğŸ“ˆ Model Evaluation
Metrics Used

Mean Absolute Error (MAE)

RÂ² Score

Actual vs Predicted visualization

Performance Summary
Model	MAE
Baseline	~4000
Linear Regression	~3500
Random Forest	~2200
XGBoost	â†“ improved
CatBoost	Best âœ…(2100)

The final model achieves a ~45% reduction in error compared to the baseline.

ğŸ“Š Visualization

An Actual vs Predicted scatter plot was used to validate:

Strong positive correlation

Reasonable dispersion around the diagonal

No signs of data leakage or overfitting

ğŸ§  Key Learnings

Model performance improves significantly with non-linear and boosting models

Feature preprocessing and leakage prevention are critical

MAE must always be interpreted relative to target scale

Extremely high RÂ² values can indicate leakage and must be validated carefully

CatBoost is highly effective for categorical-heavy retail datasets

ğŸš€ Future Enhancements

Advanced feature engineering (user-level aggregates)

Hyperparameter tuning using GridSearchCV

Model deployment using FastAPI

Real-time prediction API

ğŸ› ï¸ Tech Stack

Python

Pandas, NumPy

Matplotlib, Seaborn

scikit-learn

XGBoost

CatBoost

ğŸ“Œ Conclusion

This project demonstrates an end-to-end, industry-style machine learning workflow, progressing from simple baselines to advanced boosting models.
The final CatBoost model delivers strong and realistic performance, making this project interview-ready and portfolio-worthy.
